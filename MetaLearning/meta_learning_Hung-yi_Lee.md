# Meta Learning

- Reference
  - [Machine Learning (2019,Spring)](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html)

Meta learning = Learn to learn

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_1.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_2.png" width="30%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_3.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_4.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_5.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_6.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_7.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_8.png" width="50%" /><br/>
  Meta Learning
</div>

<br/>

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_learning_9.png" width="50%" /><br/>
  Few-shot Classification
</div>

Omniglot \[[link](https://github.com/brendenlake/omniglot)\] \[[demo](https://openai.com/blog/reptile/)\]

### MAML

Model-agnostic meta-learning for fast adaptation of deep networks \[2017, ICML, Chelsea Finn\] \[[paper](https://arxiv.org/pdf/1703.03400.pdf)\]

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_1.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_2.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_3.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_4.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_5.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_6.png" width="40%" /><br/>
  MAML
</div>

<br/>

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/MAML_real_implementation.png" width="40%" /><br/>
  MAML â€“ Real Implementation
</div>

Meta-learning for low-resource neural machine translation \[2018, arxiv, Jiatao Gu\] \[[paper](https://arxiv.org/pdf/1808.08437.pdf)\]

### Reptile

On first-order meta-learning algorithms \[2018, arxiv, Alex Nichol\] \[[paper](https://arxiv.org/pdf/1803.02999.pdf)\] \[[link](https://openai.com/blog/reptile/)\]

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/reptile_1.png" width="40%" /><br/>
  Reptile
</div>

### More

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/architecture.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/idea.png" width="50%" /><br/>
  Reptile
</div>

### Gradient Descent as LSTM

Optimization as a model for few-shot learning \[2017, ICLR, Sachin Ravi\] \[[paper](https://openreview.net/pdf?id=rJY0-Kcll)\]

Learning to learn by gradient descent by gradient descent \[2016, NIPS, Marcin Andrychowicz\] \[[paper](http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf)\]

#### Similar to gradient descent based algorithm

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_1.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_2.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_3.png" width="40%" /><br/>
  Similar to gradient descent based algorithm
</div>

<br/>

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_implementation.png" width="40%" /><br/>
  Real Implementation
</div>

#### LSTM for Gradient Descent (v2)

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_v2_1.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_lstm_v2_2.png" width="40%" /><br/>
  LSTM for Gradient Descent (v2)
</div>

### Metri-based Approach

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_1.png" width="32%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_2.png" width="30%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_3.png" width="30%" /><br/>
  Training data and their labels
</div>

<br/>

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_shot_1.png" width="40%" /><br/>
  N-way Few/One-shot Learning<br/><br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_shot_2.png" width="40%" /><br/>
  Prototypical Network<br/><br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_shot_3.png" width="40%" /><br/>
  Matching Network<br/><br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_shot_4.png" width="40%" /><br/>
  Relation Network<br/><br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/MetaLearning/images/meta_data_label_shot_5.png" width="40%" /><br/>
  Few-shot learning for imaginary data
</div>

Prototypical networks for few-shot learning \[2017, NIPS, Jake Snell\] \[[paper](http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf)\]

Matching networks for one shot learning \[2016, NIPS, Oriol Vinyals\] \[[paper](http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf)\]

Learning to compare: Relation network for few-shot learning \[2018, CVPR, Flood Sung\] \[[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sung_Learning_to_Compare_CVPR_2018_paper.pdf)\]

Low-shot learning from imaginary data \[2018, CVPR, Yu-Xiong Wang\] \[[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Low-Shot_Learning_From_CVPR_2018_paper.pdf)\]

### Train+Test as RNN















