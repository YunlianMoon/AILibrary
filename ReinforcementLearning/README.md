# Deep Reinforcement Learning

### Table of Contents
- value-based
  - <a href="#DQN">DQN</a>
  - <a href="#DoubleDQN">Double DQN</a>
  - <a href="#PrioritizedExperienceReplayDQN">Prioritized Experience Replay DQN</a>
  - <a href="#DuelingDQN">Dueling DQN</a>
- policy gradients
  - <a href="#REINFORCE">REINFORCE</a>
- actor critic
  - <a href="#ActorCritic">Actor Critic</a>
  - <a href="#DDPG">DDPG</a>
  - <a href="#A3C">A3C</a>

#### <a name="DQN">DQN</a>
full name: Deep Q network

paper: [Mnih, Volodymyr, et al. "Playing atari with deep reinforcement learning." arXiv preprint arXiv:1312.5602 (2013).](https://arxiv.org/pdf/1312.5602.pdf\))

![DQN](https://github.com/YunlianMoon/AILibrary/blob/master/ReinforcementLearning/images/DQN.svg "DQN")

#### <a name="DoubleDQN">Double DQN</a>
paper: [Van Hasselt, Hado, Arthur Guez, and David Silver. "Deep reinforcement learning with double q-learning." Thirtieth AAAI Conference on Artificial Intelligence. 2016.](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12389/11847)

![DoubleDQN](https://github.com/YunlianMoon/AILibrary/blob/master/ReinforcementLearning/images/DoubleDQN.svg "DoubleDQN")

#### <a name="PrioritizedExperienceReplayDQN">Prioritized Experience Replay DQN</a>
paper: [Schaul, Tom, et al. "Prioritized experience replay." arXiv preprint arXiv:1511.05952 (2015).](https://arxiv.org/pdf/1511.05952.pdf)

#### <a name="DuelingDQN">Dueling DQN</a>
paper: [Wang, Ziyu, et al. "Dueling network architectures for deep reinforcement learning." arXiv preprint arXiv:1511.06581 (2015).](https://arxiv.org/pdf/1511.06581.pdf)

![DuelingDQN](https://github.com/YunlianMoon/AILibrary/blob/master/ReinforcementLearning/images/DuelingDQN.svg "DuelingDQN")

#### <a name="REINFORCE">REINFORCE</a>
paper: [Sutton, Richard S., et al. "Policy gradient methods for reinforcement learning with function approximation." Advances in neural information processing systems. 2000.](http://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)

![REINFORCE](https://github.com/YunlianMoon/AILibrary/blob/master/ReinforcementLearning/images/REINFORCE.svg "REINFORCE")

#### <a name="ActorCritic">Actor Critic</a>

#### <a name="DDPG">DDPG</a>
full name: deep deterministic policy gradient

paper: [Lillicrap, Timothy P., et al. "Continuous control with deep reinforcement learning." arXiv preprint arXiv:1509.02971 (2015).](https://arxiv.org/pdf/1509.02971.pdf)

![DDPG](https://github.com/YunlianMoon/AILibrary/blob/master/ReinforcementLearning/images/DDPG.svg "DDPG")

#### <a name="A3C">A3C</a>
full name: asynchronous advantage actor critic

paper: [Mnih, Volodymyr, et al. "Asynchronous methods for deep reinforcement learning." International conference on machine learning. 2016.](http://proceedings.mlr.press/v48/mniha16.pdf)





