# Word Embedding

#### Language Model

#### N-gram

#### one-hot representation

#### Co-Occurance Vector

####  NNLM
full name: Nerual Network Language Model

#### Distributed Representation

### word2vec
Word2Vec is a group of models that tries to represent each word in a large text as a vector in a space of N dimensions (which we will call features) making similar words also be close to each other.

#### Skip-gram

#### CBOW
full name: Continuous Bag of Words

#### ELMO
full name: Embedding from Language Models

#### Encoder-Decoder

#### Transformer

#### BERT
full name: Bidirectional Encoder Representations from Transformer

