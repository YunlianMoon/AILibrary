# Long Short-Term Memory

reference: 
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)<br/>
- [Li Hongyi - ML Lecture 21-1: Recurrent Neural Network (Part I)](https://www.youtube.com/watch?v=xCGidAeyS4M)

### LSTM Networks
<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM3-chain.png" width="70%" /><br/>  
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM2-notation.png" width="70%" /><br/>
  The repeating module in an LSTM contains four interacting layers
</div>



### Step-by-Step LSTM Walk Through
<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM3-focus-f.png" width="70%" /><br/>  
  forget gate<br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM3-focus-i.png" width="70%" /><br/> 
  input gate and gate gate<br/>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM3-focus-C.png" width="70%" /><br/> 
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/images/LSTM3-focus-o.png" width="70%" /><br/>
  output gate
</div>



