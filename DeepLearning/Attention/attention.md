# Attention

- reference from [Machine Learning and having it deep and structured (2015,Fall)](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/Attain%20(v3).ecm.mp4/index.html) by Hung-yi Lee
  - Attention on Sensory Information
  - Attention on Memory
  
  
### Hung-yi Lee
#### Attention on Sensory Information
  
application:
  - Machine Translation
  - Speech Recognition
  - Image Caption Generation
  - Video Caption Generation
  - Reading Comprehension/Quesion Answering
  - Visual Question Answering
  
  
##### machine translation
  
<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/machine_translate_match.png" width="45%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/machine_translation_rnn_1.png" width="45%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/machine_translation_rnn_2.png" width="25%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/machine_translation_rnn_3.png" width="35%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/machine_translation_rnn_4.png" width="32%" /><br/>
  Attention based Machine Translation Model
</div>

#### speech recognition

Listen, attend and spell: A neural network for large vocabulary conversational speech recognition \[2016, ICASSP, William Chan\] \[[Paper](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44926.pdf)\]

#### image caption generation

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/image_caption_match.png" width="30%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/image_caption_rnn_1.png" width="30%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/image_caption_rnn_2.png" width="30%" /><br/>
  Attention based Image Caption Model
</div>

Show, attend and tell: Neural image caption generation with visual attention \[2015, ICML, Kelvin Xu\] \[[Paper](http://proceedings.mlr.press/v37/xuc15.pdf)\]

#### reading comprehension

<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/reading_comprehension.png" width="50%" /> <br/>
  Attention based Reading Comprehension Model
</div>

<br/>
<div align=center>
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/reading_comprehension_memory_network_1.png" width="40%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/arrow.jpg" width="2%" />
  <img src="https://github.com/YunlianMoon/AILibrary/blob/master/DeepLearning/Attention/images/reading_comprehension_memory_network_2.png" width="40%" /><br/>
  Attention based Reading Comprehension Model
</div>

End-to-end memory networks \[2015, NIPS, Sainbayar Sukhbaatar\] \[[Paper](https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)\]

Spatial transformer networks \[2015, NIPS, Max Jaderberg\] \[[Paper](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)\]

#### Attention on Memory

Neural turing machines \[2014, arxiv, Alex Graves\] \[[Paper](https://arxiv.org/pdf/1410.5401.pdf%20(http://Neural%20Turning%20Machines)%20)\]



  
  
  
  


