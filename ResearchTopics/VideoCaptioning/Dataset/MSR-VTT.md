# MSR-VTT

Paper: [MSR-VTT: A Large Video Description Dataset for Bridging Video and Language](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Xu_MSR-VTT_A_Large_CVPR_2016_paper.html)

Year: 2016

The MSR-VTT dataset stands for MSR-Video to Text, which is a new large-scale video benchmark for video understanding, especially the emerging task of translating video to text. This is achieved by collecting 257 popular queries from a commercial video search engine, with 118 videos for each query. In its current version, MSR-VTT provides 10K web video clips with 41.2 hours and 200K clip-sentence pairs in total, covering a comprehensive list of 20 categories and a wide variety of video content. Each clip was annotated with about 20 natural sentences.

